import { useEffect, useRef, useState, useCallback } from 'react';
import { FaceLandmarker, FilesetResolver } from '@mediapipe/tasks-vision';
import { LandmarkCompressor } from '../utils/compression';
import { FaceNormalizer } from '../core/normalizer/FaceNormalizer';
import type { Point3D, NormalizedLandmarks } from '../types';

export interface EmotionData {
  happiness: number;
  sadness: number;
  surprise: number;
  anger: number;
  neutral: number;
  timestamp: number;
}

export interface FaceLandmark {
  x: number;
  y: number;
  z?: number;
}

export interface MediaPipeState {
  isInitialized: boolean;
  isProcessing: boolean;
  error: string | null;
  landmarks: FaceLandmark[] | null;
  normalizedLandmarks: Point3D[] | null;
  normalizationData: NormalizedLandmarks | null;
  compressionStats: {
    isInitialized: boolean;
    compressionRatio: number;
  };
}

export interface MediaPipeHookOptions {
  onLandmarkData?: (data: Uint8Array, metadata: { compressionType: 'delta-delta' | 'full' }) => void;
  sendInterval?: number; // ms (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ms = 10fps)
  enableSending?: boolean;
}

// åž‹å®šç¾©ã‚’åˆ¥é€”ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
export type { EmotionData as EmotionDataType };

export const useMediaPipe = (_options: MediaPipeHookOptions = {}) => {

  const [state, setState] = useState<MediaPipeState>({
    isInitialized: false,
    isProcessing: false,
    error: null,
    landmarks: null,
    normalizedLandmarks: null,
    normalizationData: null,
    compressionStats: {
      isInitialized: false,
      compressionRatio: 0
    }
  });

  const faceLandmarkerRef = useRef<FaceLandmarker | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const compressorRef = useRef<LandmarkCompressor>(new LandmarkCompressor());
  const faceNormalizerRef = useRef<FaceNormalizer>(new FaceNormalizer());
  const sendTimerRef = useRef<NodeJS.Timeout | null>(null);

  useEffect(() => {
    const initializeMediaPipe = async () => {
      try {
        setState(prev => ({ ...prev, error: null }));

        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );

        const faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          numFaces: 1,
          minFaceDetectionConfidence: 0.45, // ç²¾åº¦ã‚’ä¸‹ã’ã¦é«˜é€ŸåŒ–
          minTrackingConfidence: 0.45,  // ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç²¾åº¦ã‚‚èª¿æ•´
          outputFaceBlendshapes: false, // ä¸è¦ãªå‡ºåŠ›ã‚’ç„¡åŠ¹åŒ–ï¼ˆæ„Ÿæƒ…æ¤œå‡ºã¯ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã§è¡Œã†ï¼‰
          outputFacialTransformationMatrixes: true // MediaPipeå…¬å¼ä»•æ§˜ã«å¾“ã£ãŸè¨­å®š
        });

        faceLandmarkerRef.current = faceLandmarker;

        setState(prev => ({
          ...prev,
          isInitialized: true,
          error: null
        }));

        console.log('MediaPipe FaceLandmarker initialized successfully');
      } catch (error) {
        console.error('Failed to initialize MediaPipe:', error);
        setState(prev => ({
          ...prev,
          error: error instanceof Error ? error.message : 'MediaPipeåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼',
          isInitialized: false
        }));
      }
    };

    initializeMediaPipe();

    return () => {
      if (faceLandmarkerRef.current) {
        faceLandmarkerRef.current.close();
        faceLandmarkerRef.current = null;
      }
    };
  }, []);

  const processVideoFrame = (video: HTMLVideoElement): void => {
    if (!faceLandmarkerRef.current || !state.isInitialized || !video || video.videoWidth === 0) {
      return;
    }

    try {
      // Don't update state here - causes infinite loop on every frame
      const results = faceLandmarkerRef.current.detectForVideo(video, performance.now());

      let landmarks: FaceLandmark[] | null = null;
      let normalizedLandmarks: Point3D[] | null = null;
      let normalizationData: NormalizedLandmarks | null = null;

      // ãƒ©ãƒ³ãƒ‰ãƒžãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆFaceNormalizerã§å®Œå…¨æ­£è¦åŒ–ï¼‰
      if (results.faceLandmarks && results.faceLandmarks.length > 0) {
        // å…ƒã®ãƒ©ãƒ³ãƒ‰ãƒžãƒ¼ã‚¯ã‚’ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã«å¤‰æ›
        const rawLandmarks: Point3D[] = results.faceLandmarks[0].map(landmark => ({
          x: landmark.x * video.videoWidth,
          y: landmark.y * video.videoHeight,
          z: landmark.z * video.videoWidth
        }));

        // transformation matrixã‚’å–å¾—ï¼ˆè¤‡æ•°ã®å¯èƒ½æ€§ã‚’è©¦ã™ï¼‰
        let transformMatrix = null;

        // DEBUG: MediaPipeã®çµæžœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ç¢ºèªï¼ˆä¸€åº¦ã ã‘ï¼‰
        if (!(window as any).mediaPipePropsLogged) {
          console.log('ðŸ” Available MediaPipe result properties:', Object.keys(results));
          (window as any).mediaPipePropsLogged = true;
        }

        // æ­£ã—ã„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£åã‚’ä½¿ç”¨ï¼ˆMediaPipeå…¬å¼ä»•æ§˜ï¼‰
        const possibleMatrixProps = [
          'facialTransformationMatrixes' // MediaPipeå…¬å¼ã®æ­£ã—ã„ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£å
        ];

        for (const prop of possibleMatrixProps) {
          if ((results as any)[prop] && (results as any)[prop].length > 0) {
            transformMatrix = (results as any)[prop][0];
            break;
          }
        }

        try {
          // FaceNormalizerã§å®Œå…¨æ­£è¦åŒ–
          normalizationData = faceNormalizerRef.current.normalize(rawLandmarks, transformMatrix);
          normalizedLandmarks = normalizationData.normalized;

          // å…ƒã®å½¢å¼ã®landmarksã‚‚ä¿æŒï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
          landmarks = rawLandmarks.map(point => ({
            x: point.x,
            y: point.y,
            z: point.z
          }));

          // ãƒ­ã‚°ã¯å‰Šé™¤ï¼ˆã‚¹ãƒ‘ãƒ é˜²æ­¢ï¼‰

        } catch (error) {
          console.error('âŒ Normalization failed:', error);
          // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå…ƒã®ãƒ©ãƒ³ãƒ‰ãƒžãƒ¼ã‚¯ã®ã¿ä½¿ç”¨
          landmarks = rawLandmarks.map(point => ({
            x: point.x,
            y: point.y,
            z: point.z
          }));
        }

        setState(prev => ({
          ...prev,
          landmarks,
          normalizedLandmarks,
          normalizationData,
          compressionStats: compressorRef.current.getCompressionStats()
        }));
      } else {
        setState(prev => ({
          ...prev,
          landmarks: null,
          normalizedLandmarks: null,
          normalizationData: null,
          compressionStats: compressorRef.current.getCompressionStats()
        }));
      }
    } catch (error) {
      console.error('Error processing video frame:', error);
      setState(prev => ({
        ...prev,
        error: error instanceof Error ? error.message : 'æ˜ åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼'
      }));
    }
  };

  // åœ§ç¸®çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆæ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ï¼‰
  const resetCompression = useCallback(() => {
    compressorRef.current.reset();
    setState(prev => ({
      ...prev,
      compressionStats: {
        isInitialized: false,
        compressionRatio: 0
      }
    }));
  }, []);

  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
  useEffect(() => {
    return () => {
      if (sendTimerRef.current) {
        clearTimeout(sendTimerRef.current);
      }
    };
  }, []);

  return {
    ...state,
    processVideoFrame,
    resetCompression,
    canvasRef,
  };
};

